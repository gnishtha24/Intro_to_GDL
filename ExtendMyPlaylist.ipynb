{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_Yvjsxj3F3f"
      },
      "source": [
        "***\n",
        "***\n",
        "\n",
        "# Extend My Playlist\n",
        "\n",
        "\n",
        "\n",
        "- This assignment we use a dataset of Spotify playlists, and build a GNN to build a playlist-track RecSys (Recommendation System). We'll use a type of layer called LightGCN for this task.\n",
        "- The dataset we have  is a small part of a much larger dataset so the free tier colab GPU can handle it.\n",
        "\n",
        "\n",
        "### Details\n",
        "- This assignment has been done in group of 3\n",
        "\n",
        "### Boilerplate -\n",
        "0. [Setting up - Installation and Data Loading](#section-0---installation-and-data-loading-0-points)\n",
        "1. [Data preprocessing ](#section-1---data-preprocessing-graded-sections-start-here)\n",
        "2. [Training and Testing ](#section-2-training-and-testing)\n",
        "3. [Training Visualisation (10 points)](#section-3---training-visualisation)\n",
        "4. [(Bonus) Embedding Visualisation](#section-4---bonus-embedding-visualisation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHY6ad043F3q"
      },
      "source": [
        "***\n",
        "\n",
        "# Code Starts Here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYow77IU3F3q"
      },
      "source": [
        "\n",
        "## Section 0 - Installation and Data Loading\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff0_hr5z3F3r"
      },
      "source": [
        "### Installation of Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy_BhyUo3F3s",
        "outputId": "9de6740a-b2ae-4a4e-a265-0a216ebc339e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n"
          ]
        }
      ],
      "source": [
        "# # If you are running this code locally, remember to comment this section after you have installed the code.\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
        "!pip install torch-geometric\n",
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REW_Eb9p3F3u"
      },
      "source": [
        "### General imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M6zzhwF3F3v"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pprint\n",
        "from pathlib import Path as Data_Path\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v33ZDDZ63F3w"
      },
      "source": [
        "### ML imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT-EuJ5m3F3w"
      },
      "outputs": [],
      "source": [
        "# Import relevant ML libraries\n",
        "from typing import Optional, Union\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding, ModuleList, Linear\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch.nn.modules.loss import _Loss\n",
        "\n",
        "from torch_geometric.nn.conv import LGConv\n",
        "from torch_geometric.typing import Adj, OptTensor, SparseTensor\n",
        "\n",
        "print(f\"Torch version: {torch.__version__}; Torch-cuda version: {torch.version.cuda};\\\n",
        "         Torch Geometric version: {torch_geometric.__version__}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBfUqDj33F3x"
      },
      "source": [
        "### Seeding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFN0I9UG3F3x"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7juelxo3F3y"
      },
      "source": [
        "### Useful Classes\n",
        "I am creating some classes that are useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJSzMmQB3F3y"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The original data was stored in JSON files, which contain playlists, which themselves contain tracks.\n",
        "Thus, we define three classes:\n",
        "  Track    : contains information for a specific track (its id, name, etc.)\n",
        "  Playlist : contains information for a specific playlist (its id, name, etc. as well as a list of Tracks)\n",
        "  JSONFile : contains the loaded json file and stores a dictionary of all of the Playlists\n",
        "\n",
        "Note: If you want to use Artist info, you may want to create an Artist class\n",
        "\"\"\"\n",
        "\n",
        "class Track:\n",
        "  \"\"\"\n",
        "  Simple class for a track, containing its attributes:\n",
        "    1. URI (a unique id)\n",
        "    2. Name\n",
        "    3. Artist info (URI and name)\n",
        "    4. Parent playlist\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, track_dict, playlist):\n",
        "    self.uri = track_dict[\"track_uri\"]\n",
        "    self.name = track_dict[\"track_name\"]\n",
        "    self.artist_uri = track_dict[\"artist_uri\"]\n",
        "    self.artist_name = track_dict[\"artist_name\"]\n",
        "    self.playlist = playlist\n",
        "\n",
        "  def __str__(self):\n",
        "    return f\"Track {self.uri} called {self.name} by {self.artist_uri} ({self.artist_name}) in playlist {self.playlist}.\"\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"Track {self.uri}\"\n",
        "\n",
        "class Playlist:\n",
        "  \"\"\"\n",
        "  Simple class for a playlist, containing its attributes:\n",
        "    1. Name (playlist and its associated index (the data is a subset, so every index hasn't been shared with you))\n",
        "    2. Title (playlist title in the Spotify dataset)\n",
        "    3. Loaded dictionary from the raw json for the playlist\n",
        "    4. Dictionary of tracks (track_uri : Track), populated by .load_tracks()\n",
        "    5. List of artists uris\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, json_data, index):\n",
        "\n",
        "    self.name = f\"playlist_{index}\"\n",
        "    self.title = json_data[\"name\"]\n",
        "    self.data = json_data\n",
        "\n",
        "    self.tracks = {}\n",
        "    self.artists = []\n",
        "\n",
        "  def load_tracks(self):\n",
        "    \"\"\" Call this function to load all of the tracks in the json data for the playlist.\"\"\"\n",
        "\n",
        "    tracks_list = self.data[\"tracks\"]\n",
        "    self.tracks = {x[\"track_uri\"] : Track(x, self.name) for x in tracks_list}\n",
        "    self.artists = [x[\"artist_uri\"] for x in tracks_list]\n",
        "\n",
        "  def __str__(self):\n",
        "    return f\"Playlist {self.name} with {len(self.tracks)} tracks loaded.\"\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"Playlist {self.name}\"\n",
        "\n",
        "class JSONFile:\n",
        "  \"\"\"\n",
        "  Simple class for a JSON file, containing its attributes:\n",
        "    1. File Name\n",
        "    2. Index to begin numbering playlists at\n",
        "    3. Loaded dictionary from the raw json for the full file\n",
        "    4. Dictionary of playlists (name : Playlist), populated by .process_file()\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, data_path, file_name, start_index):\n",
        "\n",
        "    self.file_name = file_name\n",
        "    self.start_index = start_index\n",
        "\n",
        "    with open(join(data_path, file_name)) as json_file:\n",
        "      json_data = json.load(json_file)\n",
        "    self.data = json_data\n",
        "\n",
        "    self.playlists = {}\n",
        "\n",
        "  def process_file(self):\n",
        "    \"\"\" Call this function to load all of the playlists in the json data.\"\"\"\n",
        "\n",
        "    for i, playlist_json in enumerate(self.data[\"playlists\"]):\n",
        "      playlist = Playlist(playlist_json, self.start_index + i)\n",
        "      playlist.load_tracks()\n",
        "      self.playlists[playlist.name] = playlist\n",
        "\n",
        "  def __str__(self):\n",
        "    return f\"JSON {self.file_name} has {len(self.playlists)} playlists loaded.\"\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.file_name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0an4xIuq3F3y"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fkI0Pb83F3z"
      },
      "source": [
        "- `playlist_dat.pt` is a file with a PyG Data object. This has a graph with all the data you'll need.\n",
        "- A simple `torch.load()` command will put this in your memory, as shown below. Feel free to rename this variable.\n",
        "- `playlists_idx.dat` and `tracks_idx.dat` are just pickle objects with list of node ids which are playlists and tracks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_fN6NVI3F3z"
      },
      "source": [
        "This is what (a small subset of) graph looks like, blue represents playlists, and red represents tracks\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7lOZAOJ3F3z"
      },
      "outputs": [],
      "source": [
        "graph_data = torch.load('playlist_data.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcUG5f3A3F3z"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"playlists_idx.dat\",\"rb\") as f:\n",
        "    playlists_idx = pickle.load(f)\n",
        "\n",
        "with open(\"tracks_idx.dat\",\"rb\") as f:\n",
        "    tracks_idx = pickle.load(f)\n",
        "n_playlists = len(playlists_idx)\n",
        "n_tracks = len(tracks_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqqhuIGpHxh9"
      },
      "outputs": [],
      "source": [
        "graph_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXWgXiWC3F30"
      },
      "source": [
        "### Try out some EDA\n",
        "\n",
        "What does this graph look like? What are the number of nodes? What kind of information is available to you here? Do some EDA and get comfortable. This part won't be graded, but I doubt you will be able to progress much without understanding your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxefn44K3F30"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# View the first few rows\n",
        "print(graph_data.num_nodes)\n",
        "print(graph_data.num_edges)\n",
        "print(graph_data.num_node_features)\n",
        "print(graph_data.is_directed())\n",
        "print(len(graph_data))\n",
        "print(graph_data.num_features)\n",
        "print(graph_data.num_edge_features)\n",
        "print(graph_data.num_edge_types)\n",
        "print(graph_data.num_node_types)\n",
        "print(graph_data.num_features)\n",
        "print(graph_data.has_isolated_nodes())\n",
        "print(graph_data.has_self_loops())\n",
        "print(graph_data.num_edges/graph_data.num_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6KQK8yy3F31"
      },
      "source": [
        "## Section 1 - Data Preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1iCtkCu3F32"
      },
      "source": [
        "Split the data into train-test-split sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvllOxNk3F32"
      },
      "outputs": [],
      "source": [
        "# turn the graph into a torch_geometric Data object\n",
        "\n",
        "# num_nodes = n_playlists +  n_tracks\n",
        "# edge_idx = torch.Tensor(np.array(G.edges()).T)\n",
        "# graph_data = Data(edge_index = edge_idx, num_nodes = num_nodes)\n",
        "\n",
        "# convert to train/val/test splits\n",
        "transform = RandomLinkSplit(\n",
        "    is_undirected=True,\n",
        "    add_negative_train_samples=False,\n",
        "    neg_sampling_ratio=0,\n",
        "    num_val=0.15, num_test=0.15\n",
        ")\n",
        "train_split, val_split, test_split = transform(graph_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5c0z7BVxFuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df7d235-4b6c-4de9-916a-5bf2d81898fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8254.)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "graph_data.edge_index[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLqfl_08zd83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aadf2b6-73dc-4384-cab4-843a21cd764b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 438692], num_nodes=15720, edge_label=[219346], edge_label_index=[2, 219346])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEVd8zIY2gAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e169ba1-3f44-4ee9-d5d2-bc015f7d74a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 438692], num_nodes=15720, edge_label=[47002], edge_label_index=[2, 47002])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "val_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUuaUBE22oGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdbd1d6-b0a5-43a8-beeb-3f505d545dd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 532696], num_nodes=15720, edge_label=[47002], edge_label_index=[2, 47002])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAV1zAny3F33"
      },
      "source": [
        "The dataset has data in `float32` format, but training will require to use it in `torch.int64`\n",
        "Just a reminder -\n",
        "1. Edge Index - Message Passing Edges\n",
        "2. Edge Label Index - Supervision Edges\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckD5ttUF3F33"
      },
      "outputs": [],
      "source": [
        "train_split.edge_index = train_split.edge_index.type(torch.int64)\n",
        "val_split.edge_index = val_split.edge_index.type(torch.int64)\n",
        "test_split.edge_index = test_split.edge_index.type(torch.int64)\n",
        "\n",
        "train_split.edge_label_index = train_split.edge_label_index.type(torch.int64)\n",
        "val_split.edge_label_index = val_split.edge_label_index.type(torch.int64)\n",
        "test_split.edge_label_index = test_split.edge_label_index.type(torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK_Do7EP3F33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aec5207-8549-4ed5-d777-30bf6fecd306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set has 219346 positives supervision edges\n",
            "Validation set has 47002 positive supervision edges\n",
            "Test set has 47002 positive supervision edges\n",
            "Train set has 438692 message passing edges\n",
            "Validation set has 438692 message passing edges\n",
            "Test set has 532696 message passing edges\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train set has {train_split.edge_label_index.shape[1]} positives supervision edges\")\n",
        "print(f\"Validation set has {val_split.edge_label_index.shape[1]} positive supervision edges\")\n",
        "print(f\"Test set has {test_split.edge_label_index.shape[1]} positive supervision edges\")\n",
        "\n",
        "print(f\"Train set has {train_split.edge_index.shape[1]} message passing edges\")\n",
        "print(f\"Validation set has {val_split.edge_index.shape[1]} message passing edges\")\n",
        "print(f\"Test set has {test_split.edge_index.shape[1]} message passing edges\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUR1Rpwl3F34"
      },
      "source": [
        "### The BPR Loss\n",
        "\n",
        "a new kind of Loss function for this task, so here's a class for implementing BPR, Bayesian Personalised Ranking Loss.\n",
        "\n",
        "\\begin{equation*}\n",
        "    \\text{BPR Loss}(i) = \\frac{1}{|\\mathcal{E}(i)|} \\underset{{(i, j_{+}) \\in \\mathcal{E}(i)}}{\\sum} \\log \\sigma \\left( \\text{score}(i, j_+) - \\text{score}(i, j_-) \\right)\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ksTscRh3F34"
      },
      "outputs": [],
      "source": [
        "class BPRLoss(_Loss):\n",
        "    r\"\"\"The Bayesian Personalized Ranking (BPR) loss.\n",
        "\n",
        "    The BPR loss is a pairwise loss that encourages the prediction of an\n",
        "    observed entry to be higher than its unobserved counterparts\n",
        "    (see `here <https://arxiv.org/abs/2002.02126>`__).\n",
        "\n",
        "    .. math::\n",
        "        L_{\\text{BPR}} = - \\sum_{u=1}^{M} \\sum_{i \\in \\mathcal{N}_u}\n",
        "        \\sum_{j \\not\\in \\mathcal{N}_u} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})\n",
        "        + \\lambda \\vert\\vert \\textbf{x}^{(0)} \\vert\\vert^2\n",
        "\n",
        "    where :math:`lambda` controls the :math:`L_2` regularization strength.\n",
        "    We compute the mean BPR loss for simplicity.\n",
        "\n",
        "    Args:\n",
        "        lambda_reg (float, optional): The :math:`L_2` regularization strength\n",
        "            (default: 0).\n",
        "        **kwargs (optional): Additional arguments of the underlying\n",
        "            :class:`torch.nn.modules.loss._Loss` class.\n",
        "    \"\"\"\n",
        "    __constants__ = ['lambda_reg']\n",
        "    lambda_reg: float\n",
        "\n",
        "    def __init__(self, lambda_reg: float = 0, **kwargs):\n",
        "        super().__init__(None, None, \"sum\", **kwargs)\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "    def forward(self, positives: Tensor, negatives: Tensor,\n",
        "                parameters: Tensor = None) -> Tensor:\n",
        "        r\"\"\"Compute the mean Bayesian Personalized Ranking (BPR) loss.\n",
        "\n",
        "        .. note::\n",
        "\n",
        "            The i-th entry in the :obj:`positives` vector and i-th entry\n",
        "            in the :obj:`negatives` entry should correspond to the same\n",
        "            entity (*.e.g*, user), as the BPR is a personalized ranking loss.\n",
        "\n",
        "        Args:\n",
        "            positives (Tensor): The vector of positive-pair rankings.\n",
        "            negatives (Tensor): The vector of negative-pair rankings.\n",
        "            parameters (Tensor, optional): The tensor of parameters which\n",
        "                should be used for :math:`L_2` regularization\n",
        "                (default: :obj:`None`).\n",
        "        \"\"\"\n",
        "        n_pairs = positives.size(0)\n",
        "        log_prob = F.logsigmoid(positives - negatives).sum()\n",
        "        regularization = 0\n",
        "\n",
        "        if self.lambda_reg != 0:\n",
        "            regularization = self.lambda_reg * parameters.norm(p=2).pow(2)\n",
        "\n",
        "        return (-log_prob + regularization) / n_pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhfWKMFI3F35"
      },
      "source": [
        "### The GCN class\n",
        "As mentioned, the primary model type we need here is a GCN. Use this boilerplate code to define our GCN class.\n",
        "\n",
        "As for the type of layer we need to use - It's the [LGConv](https://arxiv.org/abs/2002.02126) layer. PyG already offers this type of layer. [see here](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.LGConv.html#torch_geometric.nn.conv.LGConv).\n",
        "\n",
        "There's other types of layers available, and this boilerplate code here should make it pretty easy to call upon many different PyG layers. This however is not necessary to have a successful model or for your score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05LyrAfP3F35"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "      Here we adapt the LightGCN model from Torch Geometric for our purposes.\n",
        "      We'll be using the LGCN\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_nodes: int,\n",
        "        embedding_dim: int,\n",
        "        num_layers: int,\n",
        "        alpha: Optional[Union[float, Tensor]] = None,\n",
        "        alpha_learnable = False,\n",
        "        conv_layer = \"LGC\",\n",
        "        name = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        alpha_string = \"alpha\" if alpha_learnable else \"\"\n",
        "        self.name = f\"LGCN_{conv_layer}_{num_layers}_e{embedding_dim}_nodes{num_nodes}_{alpha_string}\"\n",
        "        self.num_nodes = num_nodes\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        if alpha_learnable == True:\n",
        "          alpha_vals = torch.rand(num_layers+1)\n",
        "          alpha = nn.Parameter(alpha_vals/torch.sum(alpha_vals))\n",
        "          print(f\"Alpha learnable, initialized to: {alpha.softmax(dim=-1)}\")\n",
        "        else:\n",
        "          if alpha is None:\n",
        "              alpha = 1. / (num_layers + 1)\n",
        "\n",
        "          if isinstance(alpha, Tensor):\n",
        "              assert alpha.size(0) == num_layers + 1\n",
        "          else:\n",
        "              alpha = torch.tensor([alpha] * (num_layers + 1))\n",
        "\n",
        "        self.register_buffer('alpha', alpha)\n",
        "\n",
        "        self.embedding = Embedding(num_nodes, embedding_dim)\n",
        "\n",
        "        # initialize convolutional layers\n",
        "        self.conv_layer = conv_layer\n",
        "        if conv_layer == \"LGC\":\n",
        "          self.convs = ModuleList([LGConv(**kwargs) for _ in range(num_layers)])\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Reset the parameters of all your layers\n",
        "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "\n",
        "    def get_embedding(self, edge_index: Adj) -> Tensor:\n",
        "        x = self.embedding.weight\n",
        "\n",
        "        weights = self.alpha.softmax(dim=-1)\n",
        "        out = x * weights[0]\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            if self.conv_layer == \"GAT\":\n",
        "              x = self.linears[i](x)\n",
        "            out = out + x * weights[i + 1]\n",
        "\n",
        "        return out\n",
        "\n",
        "    def initialize_embeddings(self, data):\n",
        "        # initialize with the data node features\n",
        "        # pass\n",
        "        self.embedding.weight.data.copy_(data.node_feature)\n",
        "\n",
        "\n",
        "    def forward(self, edge_index: Adj,\n",
        "                edge_label_index: OptTensor = None) -> Tensor:\n",
        "        # Implement the forward pass\n",
        "        if edge_label_index is None:\n",
        "            if isinstance(edge_index, SparseTensor):\n",
        "                edge_label_index = torch.stack(edge_index.coo()[:2], dim=0)\n",
        "            else:\n",
        "                edge_label_index = edge_index\n",
        "\n",
        "        out = self.get_embedding(edge_index)\n",
        "\n",
        "        return self.predict_link_embedding(out, edge_label_index)\n",
        "\n",
        "    def predict_link(self, edge_index: Adj, edge_label_index: OptTensor = None,\n",
        "                     prob: bool = False) -> Tensor:\n",
        "        pred = self(edge_index, edge_label_index).sigmoid()\n",
        "        return pred if prob else pred.round()\n",
        "\n",
        "    def predict_link_embedding(self, embed: Adj, edge_label_index: Adj) -> Tensor:\n",
        "        embed_src = embed[edge_label_index[0]]\n",
        "        embed_dst = embed[edge_label_index[1]]\n",
        "        return (embed_src * embed_dst).sum(dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "    def recommend(self, edge_index: Adj, src_index: OptTensor = None,\n",
        "                  dst_index: OptTensor = None, k: int = 1) -> Tensor:\n",
        "        # This is what you'll use for inference\n",
        "       out_src = out_dst = self.get_embedding(edge_index)\n",
        "\n",
        "       if src_index is not None:\n",
        "          out_src = out_src[src_index]\n",
        "\n",
        "       if dst_index is not None:\n",
        "          out_dst = out_dst[dst_index]\n",
        "\n",
        "       pred = out_src @ out_dst.t()\n",
        "       top_index = pred.topk(k, dim=-1).indices\n",
        "\n",
        "       if dst_index is not None:  # Map local top-indices to original indices.\n",
        "            top_index = dst_index[top_index.view(-1)].view(*top_index.size())\n",
        "\n",
        "       return top_index\n",
        "\n",
        "\n",
        "    def link_pred_loss(self, pred: Tensor, edge_label: Tensor,\n",
        "                       **kwargs) -> Tensor:\n",
        "        loss_fn = torch.nn.BCEWithLogitsLoss(**kwargs)\n",
        "        return loss_fn(pred, edge_label.to(pred.dtype))\n",
        "\n",
        "\n",
        "    def recommendation_loss(self, pos_edge_rank: Tensor, neg_edge_rank: Tensor,\n",
        "                            lambda_reg: float = 1e-4, **kwargs) -> Tensor:\n",
        "        r\"\"\"Computes the model loss for a ranking objective via the Bayesian\n",
        "        Personalized Ranking (BPR) loss.\"\"\"\n",
        "        # The BPRLoss is defined for you in the next cell.\n",
        "        loss_fn = BPRLoss(lambda_reg, **kwargs)\n",
        "        return loss_fn(pos_edge_rank, neg_edge_rank, self.embedding.weight)\n",
        "\n",
        "    def bpr_loss(self, pos_scores, neg_scores):\n",
        "      return - torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        # Used to get a summary of your model features\n",
        "        return (f'{self.__class__.__name__}({self.num_nodes}, '\n",
        "                f'{self.embedding_dim}, num_layers={self.num_layers})')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Peo94Z3F35"
      },
      "source": [
        "### Negative Sampling\n",
        "\n",
        "If you only trained the model to minimise loss however, your model would perform pretty poorly. Why so? Assign every node the same embedding, and you would technically be minimizing the loss. The solution to that usually involves negative sampling, paying attention to the nodes that do not have an edge between them and hence must not be similar.\n",
        "Here are some negative sampling approaches for you to try out. We've done the first one, you do the rest (yes this is graded)-\n",
        "1. Random, no positive check: for each positive edge coming from a playlist $p_i$, randomly draw a track $t_j$ from the full set of track nodes such that ($p_i$, $t_j$) is the negative edge. For computational efficiency, we don't check if ($p_i$, $t_j$) is actually a negative edge, though probabilistically it is very likely.\n",
        "2. Random, positive check: for each positive edge coming from a playlist $p_i$, randomly draw a track $t_j$ from the full set of track nodes such that ($p_i$, $t_j$) is the negative edge. We ensure that ($p_i$, $t_j$) is not a positive edge.\n",
        "3. Hard: for each positive edge coming from a playlist $p_i$, randomly draw a track $t_j$ from the top $k$ proportion of tracks, ranked by dot product similarity to $p_i$. For epoch 0, $k = 1$ and we lower it at each subsequent iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "242aPUac3F35"
      },
      "outputs": [],
      "source": [
        "def sample_negative_edges_nocheck(data, num_playlists, num_tracks, device=None):\n",
        "    # note computationally inefficient to check that these are indeed negative edges\n",
        "    playlists = data.edge_label_index[0, :]\n",
        "    tracks = torch.randint(num_playlists, num_playlists + num_tracks - 1, size=data.edge_label_index[1, :].size())\n",
        "\n",
        "    if playlists.get_device() != -1:  # on gpu\n",
        "        tracks = tracks.to(device)\n",
        "\n",
        "    neg_edge_index = torch.stack((playlists, tracks), dim=0)\n",
        "    neg_edge_label = torch.zeros(neg_edge_index.shape[1])\n",
        "\n",
        "    if neg_edge_index.get_device() != -1:  # on gpu\n",
        "        neg_edge_label = neg_edge_label.to(device)\n",
        "\n",
        "    return neg_edge_index, neg_edge_label\n",
        "\n",
        "def sample_negative_edges(data, num_playlists, num_tracks, device=None):\n",
        "    positive_playlists, positive_tracks = data.edge_label_index\n",
        "\n",
        "    # Create a mask tensor with the shape (num_playlists, num_tracks)\n",
        "    mask = torch.zeros(num_playlists, num_tracks, device=device, dtype=torch.bool)\n",
        "\n",
        "    # Ensure positive_playlists and positive_tracks are within bounds\n",
        "    mask_indices = (positive_playlists < num_playlists) & (positive_tracks < num_tracks)\n",
        "    positive_playlists = positive_playlists[mask_indices]\n",
        "    positive_tracks = positive_tracks[mask_indices]\n",
        "\n",
        "    mask[positive_playlists, positive_tracks] = True\n",
        "\n",
        "    # Flatten the mask tensor and get the indices of the negative edges\n",
        "    flat_mask = mask.flatten()\n",
        "    negative_indices = torch.where(~flat_mask)[0]\n",
        "\n",
        "    # Sample negative edges from the negative_indices tensor\n",
        "    sampled_negative_indices = negative_indices[\n",
        "        torch.randint(0, negative_indices.size(0), size=(positive_playlists.size(0),), device=device)\n",
        "    ]\n",
        "\n",
        "    # Convert the indices back to playlists and tracks tensors\n",
        "    playlists = torch.floor_divide(sampled_negative_indices, num_tracks)\n",
        "    tracks = torch.remainder(sampled_negative_indices, num_tracks)\n",
        "\n",
        "    # Adjust the track indices to be within the range of valid track indices\n",
        "    tracks += num_playlists\n",
        "\n",
        "    neg_edge_index = torch.stack((playlists, tracks), dim=0)\n",
        "    neg_edge_label = torch.zeros(neg_edge_index.shape[1], device=device)\n",
        "\n",
        "    return neg_edge_index, neg_edge_label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sample_hard_negative_edges(data, model, num_playlists, num_tracks, device=None, batch_size=500, frac_sample=1):\n",
        "    with torch.no_grad():\n",
        "        embeddings = model.get_embedding(data.edge_index)\n",
        "        playlists_embeddings = embeddings[:num_playlists].to(device)\n",
        "        tracks_embeddings = embeddings[num_playlists:].to(device)\n",
        "\n",
        "    positive_playlists, positive_tracks = data.edge_label_index\n",
        "    num_edges = positive_playlists.size(0)\n",
        "\n",
        "    # Create a boolean mask for all the positive edges\n",
        "    positive_mask = torch.zeros(num_playlists, num_tracks, device=device, dtype=torch.bool)\n",
        "    positive_mask[positive_playlists, positive_tracks - num_playlists] = True\n",
        "\n",
        "    neg_edges_list = []\n",
        "    neg_edge_label_list = []\n",
        "\n",
        "    for batch_start in range(0, num_edges, batch_size):\n",
        "        batch_end = min(batch_start + batch_size, num_edges)\n",
        "\n",
        "        batch_scores = torch.matmul(\n",
        "            playlists_embeddings[positive_playlists[batch_start:batch_end]], tracks_embeddings.t()\n",
        "        )\n",
        "\n",
        "        # Set the scores of the positive edges to negative infinity\n",
        "        batch_scores[positive_mask[positive_playlists[batch_start:batch_end]]] = -float(\"inf\")\n",
        "\n",
        "        # Select the top k highest scoring negative edges for each playlist in the current batch\n",
        "        # do 0.99 to filter out all pos edges which will be at the end\n",
        "        _, top_indices = torch.topk(batch_scores, int(frac_sample * 0.99 * num_tracks), dim=1)\n",
        "        selected_indices = torch.randint(0, int(frac_sample * 0.99 * num_tracks), size=(batch_end - batch_start,))\n",
        "        top_indices_selected = top_indices[torch.arange(batch_end - batch_start), selected_indices] + n_playlists\n",
        "\n",
        "        # Create the negative edges tensor for the current batch\n",
        "        neg_edges_batch = torch.stack(\n",
        "            (positive_playlists[batch_start:batch_end], top_indices_selected), dim=0\n",
        "        )\n",
        "        neg_edge_label_batch = torch.zeros(neg_edges_batch.shape[1], device=device)\n",
        "\n",
        "        neg_edges_list.append(neg_edges_batch)\n",
        "        neg_edge_label_list.append(neg_edge_label_batch)\n",
        "\n",
        "    # Concatenate the batch tensors\n",
        "    neg_edges = torch.cat(neg_edges_list, dim=1)\n",
        "    neg_edge_label = torch.cat(neg_edge_label_list)\n",
        "\n",
        "    return neg_edges, neg_edge_label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aYjdbMZ3F36"
      },
      "source": [
        "### Recall@K\n",
        "\n",
        "Using only a loss seems like a bad idea however. Most of the time it can be quite hard to interpret loss alone. So let's just also keep an eye on the Recall@K, a popular one for RecSys.\n",
        "For a playlist $i$, $P^k_i$ represents the set of the top $k$ predicted tracks for $i$ and $T_i$ the ground truth of connected tracks to playlist $i$, then we calculate\n",
        "$$\n",
        "\\text{recall}^k_i = \\frac{| P^k_i \\cap T_i | }{|T_i|}.\n",
        "$$\n",
        "If $T_i = 0$, then we assign this value to 1 (We don't really want to run into ZeroDivisionError). Note, if $T_i \\subset P_i^k$, then the recall is equal to 1. Hence, our choice of $k$ matters a lot.\n",
        "\n",
        "You'll probably want to try out multiple values of k but maybe you can start in the ballpark of 2-3% of the total tracks\n",
        "\n",
        "Note: When you evaluate this metric on the val or test set, make sure to filter the message passing edges from consideration, as the model can directly observe these.\n",
        "\n",
        "I'm implementing this for you as a freebie :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTPhHBuD3F36"
      },
      "outputs": [],
      "source": [
        "def recall_at_k(data, model, k = 10000, batch_size = 64, device = None):\n",
        "    with torch.no_grad():\n",
        "        embeddings = model.get_embedding(data.edge_index)\n",
        "        playlists_embeddings = embeddings[:n_playlists]\n",
        "        tracks_embeddings = embeddings[n_playlists:]\n",
        "\n",
        "    hits_list = []\n",
        "    relevant_counts_list = []\n",
        "\n",
        "    for batch_start in range(0, n_playlists, batch_size):\n",
        "        batch_end = min(batch_start + batch_size, n_playlists)\n",
        "        batch_playlists_embeddings = playlists_embeddings[batch_start:batch_end]\n",
        "\n",
        "        # Calculate scores for all possible item pairs\n",
        "        scores = torch.matmul(batch_playlists_embeddings, tracks_embeddings.t())\n",
        "\n",
        "        # Set the scores of message passing edges to negative infinity\n",
        "        mp_indices = ((data.edge_index[0] >= batch_start) & (data.edge_index[0] < batch_end)).nonzero(as_tuple=True)[0]\n",
        "        scores[data.edge_index[0, mp_indices] - batch_start, data.edge_index[1, mp_indices] - n_playlists] = -float(\"inf\")\n",
        "\n",
        "        # Find the top k highest scoring items for each playlist in the batch\n",
        "        _, top_k_indices = torch.topk(scores, k, dim=1)\n",
        "\n",
        "        # Ground truth supervision edges\n",
        "        ground_truth_edges = data.edge_label_index\n",
        "\n",
        "        # Create a mask to indicate if the top k items are in the ground truth supervision edges\n",
        "        mask = torch.zeros(scores.shape, device=device, dtype=torch.bool)\n",
        "        gt_indices = ((ground_truth_edges[0] >= batch_start) & (ground_truth_edges[0] < batch_end)).nonzero(as_tuple=True)[0]\n",
        "        mask[ground_truth_edges[0, gt_indices] - batch_start, ground_truth_edges[1, gt_indices] - n_playlists] = True\n",
        "\n",
        "        # Check how many of the top k items are in the ground truth supervision edges\n",
        "        hits = mask.gather(1, top_k_indices).sum(dim=1)\n",
        "        hits_list.append(hits)\n",
        "\n",
        "        # Calculate the total number of relevant items for each playlist in the batch\n",
        "        relevant_counts = torch.bincount(ground_truth_edges[0, gt_indices] - batch_start, minlength=batch_end - batch_start)\n",
        "        relevant_counts_list.append(relevant_counts)\n",
        "\n",
        "    # Compute recall@k\n",
        "    hits_tensor = torch.cat(hits_list, dim=0)\n",
        "    relevant_counts_tensor = torch.cat(relevant_counts_list, dim=0)\n",
        "    # Handle division by zero case\n",
        "    recall_at_k = torch.where(\n",
        "        relevant_counts_tensor != 0,\n",
        "        hits_tensor.true_divide(relevant_counts_tensor),\n",
        "        torch.ones_like(hits_tensor)\n",
        "    )\n",
        "    # take average\n",
        "    recall_at_k = torch.mean(recall_at_k)\n",
        "\n",
        "    if recall_at_k.numel() == 1:\n",
        "        return recall_at_k.item()\n",
        "    else:\n",
        "        raise ValueError(\"recall_at_k contains more than one item.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se9b8uTj3F36"
      },
      "source": [
        "### ROC AUC Score\n",
        "\n",
        "Finally, let's calculate the ROC AUC score for the binary predictions, which provides a measure of the efficiency of our model at distinguishing `true' track-playlist edges from non-existing ones. The higher this score, the better (a perfect score is achieved when ROC AUC = 1). This is done for you here -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fg0Sxue3F37"
      },
      "outputs": [],
      "source": [
        "\n",
        "def metrics(labels, preds):\n",
        "    unique_classes = len(torch.unique(labels))\n",
        "\n",
        "    roc = roc_auc_score(labels.flatten().cpu().numpy(), preds.flatten().data.cpu().numpy())\n",
        "    return roc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIfZgfeD3F37"
      },
      "source": [
        "## Section 2 Training and Testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV5p1tvM3F4B"
      },
      "source": [
        "Finally. It's time to write your train and test functions for training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mrwQcL93F4B"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "def train(datasets, model, optimizer, loss_fn, args, neg_samp = \"random\"):\n",
        "  print(f\"Beginning training for {model.name}\")\n",
        "\n",
        "  train_data = datasets[\"train\"]\n",
        "  val_data = datasets[\"val\"]\n",
        "\n",
        "  stats = {\n",
        "      'train': {\n",
        "        'loss': [],\n",
        "        'roc' : []\n",
        "      },\n",
        "      'val': {\n",
        "        'loss': [],\n",
        "        'recall': [],\n",
        "        'roc' : []\n",
        "      }\n",
        "\n",
        "  }\n",
        "  val_neg_edge, val_neg_label = None, None\n",
        "  for epoch in range(args[\"epochs\"]): # loop over each epoch\n",
        "    # Is your model ready?\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Negative sample the data - different methods may need different code\n",
        "    if neg_samp == \"random\":\n",
        "      neg_edge_index, neg_edge_label = sample_negative_edges(train_data, n_playlists, n_tracks, args[\"device\"])\n",
        "    elif neg_samp == \"hard\":\n",
        "      if epoch % 5 == 0:\n",
        "        neg_edge_index, neg_edge_label = sample_hard_negative_edges(\n",
        "            train_data, model, n_playlists, n_tracks, args[\"device\"], batch_size = 500,\n",
        "            frac_sample = 1 - (0.5 * epoch / args[\"epochs\"])\n",
        "        )\n",
        "\n",
        "    # calculate embedding\n",
        "    embed = model.get_embedding(train_data.edge_index)\n",
        "    # calculate pos, negative scores using embedding\n",
        "    pos_scores = model.predict_link_embedding(embed, train_data.edge_label_index)\n",
        "    neg_scores = model.predict_link_embedding(embed, neg_edge_index)\n",
        "    # concatenate pos, neg scores together and evaluate loss\n",
        "    scores = torch.cat((pos_scores, neg_scores), dim = 0)\n",
        "    labels = torch.cat((train_data.edge_label, neg_edge_label), dim = 0)\n",
        "\n",
        "    # calculate loss function\n",
        "    if loss_fn == \"BCE\":\n",
        "      loss = model.link_pred_loss(scores, labels)\n",
        "    elif loss_fn == \"BPR\":\n",
        "      loss = model.recommendation_loss(pos_scores, neg_scores, lambda_reg = 0)\n",
        "\n",
        "\n",
        "    train_roc = metrics(labels, scores)\n",
        "\n",
        "    # Learn from your mistakes\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Test on the validation set\n",
        "    val_loss, val_roc, val_neg_edge, val_neg_label = test(model, val_data, loss_fn, neg_samp, epoch, val_neg_edge, val_neg_label\n",
        "    )\n",
        "\n",
        "    # I mean it'd be useless if you didn't even save the results\n",
        "    stats['train']['loss'].append(loss)\n",
        "    stats['train']['roc'].append(train_roc)\n",
        "    stats['val']['loss'].append(val_loss)\n",
        "    stats['val']['roc'].append(val_roc)\n",
        "\n",
        "    print(f\"Epoch {epoch}; Train loss {loss}; Val loss {val_loss}; Train ROC {train_roc}; Val ROC {val_roc}\")\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      # calculate recall @ K - !ADJUST K!\n",
        "      val_recall = recall_at_k(val_data, model, k = 10000, device = args[\"device\"])\n",
        "      print(f\"Val recall {val_recall}\")\n",
        "      stats['val']['recall'].append(val_recall)\n",
        "\n",
        "  pickle.dump(stats, open(f\"model_stats/{model.name}_{loss_fn}_{neg_samp}.pkl\", \"wb\"))\n",
        "  return stats\n",
        "\n",
        "def test(model, data, loss_fn, neg_samp, epoch = 0, neg_edge_index = None, neg_edge_label = None):\n",
        "\n",
        "  # I mean pretty similar now\n",
        "  # Is your model ready to evaluate?\n",
        "\n",
        "  with torch.no_grad(): # want to save RAM\n",
        "\n",
        "    # conduct negative sampling - different modes may need different code too\n",
        "    if neg_samp == \"random\":\n",
        "      neg_edge_index, neg_edge_label = sample_negative_edges(data, n_playlists, n_tracks, training_args[\"device\"])\n",
        "    elif neg_samp == \"hard\":\n",
        "      if epoch % 5 == 0 or neg_edge_index is None:\n",
        "        neg_edge_index, neg_edge_label = sample_hard_negative_edges(\n",
        "            data, model, n_playlists, n_tracks, training_args[\"device\"], batch_size = 500,\n",
        "            frac_sample = 1 - (0.5 * epoch / training_args[\"epochs\"]))\n",
        "    # obtain model embedding\n",
        "    embed = model.get_embedding(data.edge_index)\n",
        "    # calculate pos, neg scores using embedding\n",
        "    pos_scores = model.predict_link_embedding(embed, data.edge_label_index)\n",
        "    neg_scores = model.predict_link_embedding(embed, neg_edge_index)\n",
        "    # concatenate pos, neg scores together and evaluate loss\n",
        "    scores = torch.cat((pos_scores, neg_scores), dim = 0)\n",
        "    labels = torch.cat((data.edge_label, neg_edge_label), dim = 0)\n",
        "    # calculate loss - BCE was the default loss, while BPR is the new loss\n",
        "    if loss_fn == \"BCE\":\n",
        "      loss = model.link_pred_loss(scores, labels)\n",
        "    elif loss_fn == \"BPR\":\n",
        "      loss = model.recommendation_loss(pos_scores, neg_scores, lambda_reg = 0)\n",
        "\n",
        "    roc = metrics(labels, scores)\n",
        "\n",
        "  return loss, roc, neg_edge_index, neg_edge_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znFZNUgl3F4B"
      },
      "source": [
        "### Arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jJU90ju3F4C"
      },
      "source": [
        "Maybe put your splits in a dict for easy access?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMvDloVI3F4C"
      },
      "outputs": [],
      "source": [
        "datasets = {\n",
        "    'train':train_split,\n",
        "    'val':val_split,\n",
        "    'test': test_split\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai_-4rWp3F4C"
      },
      "outputs": [],
      "source": [
        "training_args = {\n",
        "    'device' : 'cpu',  # For the love of God, please do use a GPU though.\n",
        "    'num_layers' :  3,                      # Do you think this is a good choice?\n",
        "    'emb_size' : 64,\n",
        "    'weight_decay': 1e-5,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 301\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdX6i47K3F4C"
      },
      "source": [
        "### Model Initialisation\n",
        "Initialise your model with the parameters and nodes and whatever.\n",
        "\n",
        "The Adam optimizer should work just fine for the task, so initialise that well as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsENfTOP3F4C"
      },
      "outputs": [],
      "source": [
        "# initialize model and and optimizer\n",
        "num_nodes = n_playlists + n_tracks\n",
        "model = GCN(\n",
        "    num_nodes = num_nodes, num_layers = training_args['num_layers'],\n",
        "    embedding_dim = training_args[\"emb_size\"], conv_layer = \"LGC\"\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=training_args['lr'], weight_decay=training_args['weight_decay'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RVpR9-Y3F4D"
      },
      "source": [
        "It's time to put this data on a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHCxcS463F4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b42af68-158c-477b-8e54-e290efb391fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN(15720, 64, num_layers=3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "playlists_idx = torch.Tensor(playlists_idx).type(torch.int64).to(training_args[\"device\"])\n",
        "tracks_idx =torch.Tensor(tracks_idx).type(torch.int64).to(training_args[\"device\"])\n",
        "\n",
        "datasets['train'].to(training_args['device'])\n",
        "datasets['val'].to(training_args['device'])\n",
        "datasets['test'].to(training_args['device'])\n",
        "model.to(training_args[\"device\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Pfpx4A3F4D"
      },
      "source": [
        "The below code defines the directory to store the epoch-wise stats of your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHAot6oL3F4D"
      },
      "outputs": [],
      "source": [
        "# create directory to save model_stats\n",
        "MODEL_STATS_DIR = \"model_stats\"\n",
        "if not os.path.exists(MODEL_STATS_DIR):\n",
        "  os.makedirs(MODEL_STATS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BesPMlyfwsvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQCjIG_n3F4E"
      },
      "source": [
        "### Call train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3n4qhpZ3F4E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "dc698e6f-c69d-42ec-92c7-fe110eca0b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning training for LGCN_LGC_3_e64_nodes15720_\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-9032b6321b4d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BPR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_samp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# train(datasets, model, optimizer, \"BPR\", args, neg_samp = \"random\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-0cc3dbfd3e52>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(datasets, model, optimizer, loss_fn, args, neg_samp)\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink_pred_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"BPR\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommendation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-9710e45c0ea3>\u001b[0m in \u001b[0;36mrecommendation_loss\u001b[0;34m(self, pos_edge_rank, neg_edge_rank, lambda_reg, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# The BPRLoss is defined for you in the next cell.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBPRLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_edge_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_edge_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbpr_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-857421dd79cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, positives, negatives, parameters)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \"\"\"\n\u001b[1;32m     46\u001b[0m         \u001b[0mn_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositives\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mregularization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (219346) must match the size of tensor b (0) at non-singleton dimension 0"
          ]
        }
      ],
      "source": [
        "train(datasets, model, optimizer, \"BPR\", training_args, neg_samp = \"random\")\n",
        "# train(datasets, model, optimizer, \"BPR\", args, neg_samp = \"random\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1PeP_Mf3F4E"
      },
      "source": [
        "### Call test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AymZHJYA3F4E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "d80de4a3-de07-457f-bc57-e23323729a46"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-91133cf47f35>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BPR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_samp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-0cc3dbfd3e52>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, data, loss_fn, neg_samp, epoch, neg_edge_index, neg_edge_label)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink_pred_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"BPR\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommendation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-9710e45c0ea3>\u001b[0m in \u001b[0;36mrecommendation_loss\u001b[0;34m(self, pos_edge_rank, neg_edge_rank, lambda_reg, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# The BPRLoss is defined for you in the next cell.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBPRLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_edge_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_edge_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbpr_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-857421dd79cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, positives, negatives, parameters)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \"\"\"\n\u001b[1;32m     46\u001b[0m         \u001b[0mn_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositives\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mregularization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (47002) must match the size of tensor b (0) at non-singleton dimension 0"
          ]
        }
      ],
      "source": [
        "test(model, datasets['test'], \"BPR\", neg_samp = \"random\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1I0HbTN3F4G"
      },
      "source": [
        "### Pipeline Simplification\n",
        "\n",
        "Instead of having to call everything one by one, let's package this training process into a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocrww8be3F4H"
      },
      "outputs": [],
      "source": [
        "def init_model(conv_layer, args, alpha = False):\n",
        "  num_nodes = n_playlists + n_tracks\n",
        "  model = GCN(\n",
        "      num_nodes = num_nodes, num_layers = args['num_layers'],\n",
        "      embedding_dim = args[\"emb_size\"], conv_layer = conv_layer,\n",
        "      alpha_learnable = alpha\n",
        "  )\n",
        "  model.to(args[\"device\"])\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "  return model, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9zTH4Lr3F4I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "47342f50-f809-47b9-c363-984e23793031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning training for LGCN_LGC_4_e64_nodes15720_\n",
            "Epoch 0; Train loss 0.6931362152099609; Val loss 0.6931349635124207; Train ROC 0.6313618443339448; Val ROC 0.756527040013748\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-31ddc453291b>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_layers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LGC\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlgc_stats_hard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_samp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_samp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"model_stats/{model.name}_{loss_fn}_{neg_samp}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-0cc3dbfd3e52>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(datasets, model, optimizer, loss_fn, args, neg_samp)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0;31m# calculate recall @ K - !ADJUST K!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       \u001b[0mval_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Val recall {val_recall}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_recall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-402d49b6196f>\u001b[0m in \u001b[0;36mrecall_at_k\u001b[0;34m(data, model, k, batch_size, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Find the top k highest scoring items for each playlist in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Ground truth supervision edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
          ]
        }
      ],
      "source": [
        "## For example:\n",
        "\n",
        "# using BPR loss\n",
        "loss_fn = \"BPR\"\n",
        "\n",
        "# using hard sampling\n",
        "neg_samp = \"hard\"\n",
        "\n",
        "# Num epochs, layers, etc.\n",
        "training_args['epochs'] = 301\n",
        "training_args['num_layers'] = 4\n",
        "model, optimizer = init_model(\"LGC\", training_args)\n",
        "lgc_stats_hard = train(datasets, model, optimizer, loss_fn, training_args, neg_samp = neg_samp)\n",
        "torch.save(model.state_dict(), f\"model_stats/{model.name}_{loss_fn}_{neg_samp}.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcZZnWlk3F4I"
      },
      "source": [
        "### Tuning\n",
        "\n",
        "Use the simplified pipeline to train a couple of combinations of the model - changing the following variables (Do atleast 3 of each)\n",
        "\n",
        "1. Negative Sampling Method (You should have 3 of them)\n",
        "2. Number of Layers (<10 always)\n",
        "3. Number of Epochs (vary by 100 atleast)\n",
        "\n",
        "Be sure to save the results into different files. We'll use them in the next section to visualise better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEu4hrAw3F4J"
      },
      "outputs": [],
      "source": [
        "# If you had to stop for whatever reason, you can always reload the stats here! (just uncomment and change to correct paths)\n",
        "lgc_stats = pickle.load(open(f\"{MODEL_STATS_DIR}/LGCN_LGC_4_e64_nodes34810__BPR_random.pkl\", \"rb\"))\n",
        "lgc_stats_hard = pickle.load(open(f\"{MODEL_STATS_DIR}/LGCN_LGC_4_e64_nodes34810__BPR_hard.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpDiKsW03F4N"
      },
      "outputs": [],
      "source": [
        "# Reduce 64-dim embeddings to 3-dim using umap\n",
        "umap_embs = [] # dimensionally reduced embeddings\n",
        "epoch_str = [] # what epoch produced the embeddings\n",
        "\n",
        "# Directory contianing the selected model embeddings\n",
        "model_dir = \"model_path/your_directory_name\"\n",
        "\n",
        "for filename in tqdm(sorted(os.listdir(join(os.getcwd(), model_dir)),\n",
        "                       key=lambda name: int(name[:-3].split('_')[-1]))):\n",
        "  embs = torch.load(join(os.getcwd(), model_dir, filename), map_location=torch.device('cpu')).detach().cpu().numpy()\n",
        "  embs = embs[:n_playlists]\n",
        "  u = None # Do Something\n",
        "  umap_embs.append(u)\n",
        "  epoch_str.append(filename[:-3].split('_')[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXhwzfLf3F4O"
      },
      "source": [
        "### Prep to Plot\n",
        "Now we need to pass these to our plotting library, which needs the dimensions separately.\n",
        "\n",
        "`extract_dim(dim)` will return the values for a single dimension `dim`\n",
        "\n",
        "`compute_min_max(dim,h)` should return the limits of the values on a dimension. Automatic detection by matplotlib may lead to poorly scaled graphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH8nayEH3F4O"
      },
      "outputs": [],
      "source": [
        "# Separate the embeddings dimensions for plotting\n",
        "n = len(umap_embs)\n",
        "n_emb = len(umap_embs[0])\n",
        "\n",
        "def extract_dim(dim):\n",
        "  \"\"\"Given a dim index, return just that dim of umap_embs\"\"\"\n",
        "  return [None]\n",
        "\n",
        "x = extract_dim(0)\n",
        "y = extract_dim(1)\n",
        "z = extract_dim(2)\n",
        "\n",
        "def compute_min_max(dim):\n",
        "  \"\"\"Given a dim index, compute dim limits\"\"\"\n",
        "  return None,None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMQjAkbM3F4P"
      },
      "source": [
        "### Time to plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrmF_gG83F4P"
      },
      "source": [
        "Complete this function that will plot and update the visualisation of the embeddings over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc90fc8S3F4P"
      },
      "outputs": [],
      "source": [
        "def plot_embeddings(select_idx=None, color=None):\n",
        "  \"\"\"\n",
        "  Plot the playlist embeddings.\n",
        "  Optional parameters: select_idx, color are the selected\n",
        "  indices to plot and the associated color mappings\n",
        "  \"\"\"\n",
        "  # Indecies of embeddings - There are other ways to do it\n",
        "  idx = [None]\n",
        "\n",
        "  # Set up plot\n",
        "  fig = plt.figure(figsize = (10, 10))\n",
        "  subplt = plt.axes(projection =\"3d\")\n",
        "\n",
        "  # Initialize the scatter plot\n",
        "  my_sct = subplt.scatter(x[idx[0]], y[idx[0]], z[idx[0]],\n",
        "                          alpha = 0.8, marker ='o')\n",
        "  # Set axis limit\n",
        "  subplt.set_xlim(compute_min_max(x))\n",
        "  subplt.set_xlabel('x')\n",
        "  subplt.set_ylim(compute_min_max(y))\n",
        "  subplt.set_xlabel('y')\n",
        "  subplt.set_zlim(compute_min_max(z))\n",
        "  subplt.set_xlabel('z')\n",
        "\n",
        "  # Define animation update funcion\n",
        "  def update(itr, xa, ya, za, t):\n",
        "    i = idx[itr]\n",
        "    subplt.set_title('Embedding Epoch: ' + epoch_str[i])\n",
        "    xyz = None\n",
        "    my_sct._offsets3d = xyz\n",
        "    return my_sct\n",
        "\n",
        "  # Create animation\n",
        "  ani = animation.FuncAnimation(fig, update,\n",
        "                                fargs=(x, y, z),\n",
        "                                interval=500,\n",
        "                                save_count=len(idx))\n",
        "  video = ani.to_html5_video()\n",
        "  html = display.HTML(video)\n",
        "  display.display(html)\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR_m1DH73F4P"
      },
      "source": [
        "# End\n",
        "\n",
        "And that's it! You could go one step further by poking around this data and plotting artists in different colours, to see if the embeddings are separating out artists whose styles don't match. We aren't grading you for that however.\n",
        "\n",
        "Hopefully you had some fun with this exercise. You could try running your model on newer Spotify data and seeing what happens. Maybe if you built an inference function you could also test it on your own playlists.\n",
        "\n",
        "Traditional ML architechture struggles to handle these kinds of tasks, as the data is related in a graphical structure and the data itself is a complex sequence which would be hard to analyse to generate embeddings for this use case. The upcoming topics will see us build even more on this idea, scaling your models for far larger datasets, poking around the internals of a GNN Model and the power of message passing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEEDOaqG3F4Q"
      },
      "source": [
        "***\n",
        "***"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}